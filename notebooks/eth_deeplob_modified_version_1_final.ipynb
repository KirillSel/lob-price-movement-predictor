{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":411838,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":336241,"modelId":357245}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas_market_calendars","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1T9hIh27am0","outputId":"06dbacd8-4c16-417b-c058-de312f83e6c1","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:42:40.462486Z","iopub.execute_input":"2025-05-25T16:42:40.462876Z","iopub.status.idle":"2025-05-25T16:42:47.956380Z","shell.execute_reply.started":"2025-05-25T16:42:40.462844Z","shell.execute_reply":"2025-05-25T16:42:47.954761Z"}},"outputs":[{"name":"stdout","text":"Collecting pandas_market_calendars\n  Downloading pandas_market_calendars-5.1.0-py3-none-any.whl.metadata (9.6 kB)\nRequirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2.2.3)\nRequirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2025.2)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pandas_market_calendars) (2.9.0.post0)\nCollecting exchange-calendars>=3.3 (from pandas_market_calendars)\n  Downloading exchange_calendars-4.10.1-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.26.4)\nCollecting pyluach (from exchange-calendars>=3.3->pandas_market_calendars)\n  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.0.0)\nCollecting korean_lunar_calendar (from exchange-calendars>=3.3->pandas_market_calendars)\n  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1->pandas_market_calendars) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->pandas_market_calendars) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas_market_calendars) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->exchange-calendars>=3.3->pandas_market_calendars) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->exchange-calendars>=3.3->pandas_market_calendars) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->exchange-calendars>=3.3->pandas_market_calendars) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->exchange-calendars>=3.3->pandas_market_calendars) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->exchange-calendars>=3.3->pandas_market_calendars) (2024.2.0)\nDownloading pandas_market_calendars-5.1.0-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading exchange_calendars-4.10.1-py3-none-any.whl (200 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\nDownloading pyluach-2.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: korean_lunar_calendar, pyluach, exchange-calendars, pandas_market_calendars\nSuccessfully installed exchange-calendars-4.10.1 korean_lunar_calendar-0.3.1 pandas_market_calendars-5.1.0 pyluach-2.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -U gdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Npz8Raejvb7Y","outputId":"9cf483dc-5268-48f5-f63f-f38de5ed8f32","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:42:47.957889Z","iopub.execute_input":"2025-05-25T16:42:47.958171Z","iopub.status.idle":"2025-05-25T16:42:52.252751Z","shell.execute_reply.started":"2025-05-25T16:42:47.958142Z","shell.execute_reply":"2025-05-25T16:42:52.251290Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, concatenate, LSTM, Reshape, Dense, Bidirectional, Attention, Permute, Multiply, Lambda, RepeatVector, BatchNormalization, Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\nfrom keras.layers import Softmax, MultiHeadAttention, LayerNormalization, Add\nfrom keras.saving import register_keras_serializable\nimport tensorflow.keras.backend as K\n\nimport pandas_market_calendars as mcal","metadata":{"id":"TM27oi-366FJ","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:42:52.254011Z","iopub.execute_input":"2025-05-25T16:42:52.254376Z","iopub.status.idle":"2025-05-25T16:43:15.228087Z","shell.execute_reply.started":"2025-05-25T16:42:52.254329Z","shell.execute_reply":"2025-05-25T16:43:15.227049Z"}},"outputs":[{"name":"stderr","text":"2025-05-25 16:42:56.232204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748191376.543262      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748191376.633375      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nimport random\n\nSEED = 2025\n\nos.environ['PYTHONHASHSEED'] = str(SEED)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:15.230509Z","iopub.execute_input":"2025-05-25T16:43:15.231045Z","iopub.status.idle":"2025-05-25T16:43:15.238191Z","shell.execute_reply.started":"2025-05-25T16:43:15.231015Z","shell.execute_reply":"2025-05-25T16:43:15.236962Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:15.239631Z","iopub.execute_input":"2025-05-25T16:43:15.240243Z","iopub.status.idle":"2025-05-25T16:43:15.338673Z","shell.execute_reply.started":"2025-05-25T16:43:15.240201Z","shell.execute_reply":"2025-05-25T16:43:15.337559Z"}},"outputs":[{"name":"stdout","text":"2.18.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def moving_average(x, k):\n    return np.convolve(x, np.ones(k), 'valid') / k\n\ndef compute_mid_price_changes(daily_data_dict, date_list, k):\n    all_changes = []\n    for date in date_list:\n        price_bid = daily_data_dict[date][:, 0]\n        size_bid = daily_data_dict[date][:, 1]\n        price_ask = daily_data_dict[date][:, 2]\n        size_ask = daily_data_dict[date][:, 3]\n        mid_price = (price_ask * size_bid + price_bid * size_ask) / (size_ask + size_bid)\n\n        future_avg = moving_average(mid_price, k)[1:]  # Skip current step\n        current = mid_price[:-k]\n        pct_change = (future_avg - current) / current\n        all_changes.extend(pct_change)\n    return np.array(all_changes)","metadata":{"id":"AAfOwiEqAofr","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:15.340158Z","iopub.execute_input":"2025-05-25T16:43:15.340529Z","iopub.status.idle":"2025-05-25T16:43:15.364023Z","shell.execute_reply.started":"2025-05-25T16:43:15.340483Z","shell.execute_reply":"2025-05-25T16:43:15.362993Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import gdown\n\nfile_id = \"1Awq8DwZovxzNuSSg2xGOKE56ZKYaqjKw\"\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", output=\"combined_orderbooks_eth_large.csv\", quiet=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"6asXnAtMvoM3","outputId":"f9b426b6-2d11-450b-c524-0fd341addfa9","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:15.365252Z","iopub.execute_input":"2025-05-25T16:43:15.365542Z","iopub.status.idle":"2025-05-25T16:43:21.710836Z","shell.execute_reply.started":"2025-05-25T16:43:15.365515Z","shell.execute_reply":"2025-05-25T16:43:21.709251Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1Awq8DwZovxzNuSSg2xGOKE56ZKYaqjKw\nFrom (redirected): https://drive.google.com/uc?id=1Awq8DwZovxzNuSSg2xGOKE56ZKYaqjKw&confirm=t&uuid=4c3f02c4-7467-40e0-ad10-4982834d2601\nTo: /kaggle/working/combined_orderbooks_eth_large.csv\n100%|██████████| 234M/234M [00:02<00:00, 107MB/s]  \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'combined_orderbooks_eth_large.csv'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df = pd.read_csv(\"combined_orderbooks_eth_large.csv\")","metadata":{"id":"Rlb33x3rBrP2","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:21.712191Z","iopub.execute_input":"2025-05-25T16:43:21.712962Z","iopub.status.idle":"2025-05-25T16:43:27.518305Z","shell.execute_reply.started":"2025-05-25T16:43:21.712929Z","shell.execute_reply":"2025-05-25T16:43:27.517059Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"33tIGTekqQFQ","outputId":"e0f1f9bc-a5f3-4b13-e008-28e74c5a5b6b","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:27.519410Z","iopub.execute_input":"2025-05-25T16:43:27.519687Z","iopub.status.idle":"2025-05-25T16:43:27.799505Z","shell.execute_reply.started":"2025-05-25T16:43:27.519664Z","shell.execute_reply":"2025-05-25T16:43:27.797580Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         timestamp  bid_price_1  bid_size_1  ask_price_1  ask_size_1  \\\n0       1745798400      1790.31       38.59      1790.32       15.04   \n1       1745798401      1790.31       38.71      1790.32       14.93   \n2       1745798402      1790.31       18.98      1790.32       27.39   \n3       1745798403      1790.31       27.70      1790.32        9.89   \n4       1745798404      1790.31       27.58      1790.32       10.34   \n...            ...          ...         ...          ...         ...   \n863996  1746662396      1810.48       52.96      1810.49       62.14   \n863997  1746662397      1810.48        6.68      1810.49       74.63   \n863998  1746662398      1810.48       19.02      1810.49       55.80   \n863999  1746662399      1810.26        4.74      1810.27       93.51   \n864000  1746662400      1810.26        7.95      1810.27      100.01   \n\n        bid_price_2  bid_size_2  ask_price_2  ask_size_2  bid_price_3  ...  \\\n0           1790.30        0.68      1790.34        0.08      1790.28  ...   \n1           1790.30        0.68      1790.34        0.08      1790.28  ...   \n2           1790.28        0.02      1790.33        0.03      1790.26  ...   \n3           1790.28        0.02      1790.34        0.08      1790.26  ...   \n4           1790.28        0.02      1790.34        0.08      1790.26  ...   \n...             ...         ...          ...         ...          ...  ...   \n863996      1810.47        1.53      1810.50        0.01      1810.45  ...   \n863997      1810.47        0.02      1810.50        0.01      1810.45  ...   \n863998      1810.46        0.02      1810.50        0.01      1810.45  ...   \n863999      1810.25        0.02      1810.30        2.95      1810.24  ...   \n864000      1810.25        0.02      1810.29        3.18      1810.24  ...   \n\n        ask_price_8  ask_size_8  bid_price_9  bid_size_9  ask_price_9  \\\n0           1790.43        0.02      1790.21        0.02      1790.45   \n1           1790.43        0.02      1790.21        0.02      1790.45   \n2           1790.41        1.00      1790.20        1.12      1790.43   \n3           1790.43        0.02      1790.20        1.12      1790.45   \n4           1790.43        0.02      1790.20        1.12      1790.45   \n...             ...         ...          ...         ...          ...   \n863996      1810.58        5.06      1810.36        0.02      1810.59   \n863997      1810.59       16.34      1810.36        0.02      1810.60   \n863998      1810.59       16.34      1810.36        8.30      1810.60   \n863999      1810.38        0.01      1810.13        3.87      1810.40   \n864000      1810.36       10.91      1810.13        0.03      1810.37   \n\n        ask_size_9  bid_price_10  bid_size_10  ask_price_10  ask_size_10  \n0             0.04       1790.20         1.12       1790.47         0.02  \n1             0.04       1790.20         1.12       1790.47         0.02  \n2             0.02       1790.19         0.16       1790.45         0.02  \n3             0.02       1790.19         0.16       1790.47         0.02  \n4             0.02       1790.19         0.16       1790.47         0.02  \n...            ...           ...          ...           ...          ...  \n863996       16.34       1810.35         6.29       1810.60         1.97  \n863997        1.97       1810.35         6.29       1810.61         0.03  \n863998        1.97       1810.35         6.29       1810.61         0.03  \n863999        1.97       1810.12         0.17       1810.41         0.30  \n864000       23.04       1810.12         0.17       1810.38         0.01  \n\n[864001 rows x 41 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>bid_price_1</th>\n      <th>bid_size_1</th>\n      <th>ask_price_1</th>\n      <th>ask_size_1</th>\n      <th>bid_price_2</th>\n      <th>bid_size_2</th>\n      <th>ask_price_2</th>\n      <th>ask_size_2</th>\n      <th>bid_price_3</th>\n      <th>...</th>\n      <th>ask_price_8</th>\n      <th>ask_size_8</th>\n      <th>bid_price_9</th>\n      <th>bid_size_9</th>\n      <th>ask_price_9</th>\n      <th>ask_size_9</th>\n      <th>bid_price_10</th>\n      <th>bid_size_10</th>\n      <th>ask_price_10</th>\n      <th>ask_size_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1745798400</td>\n      <td>1790.31</td>\n      <td>38.59</td>\n      <td>1790.32</td>\n      <td>15.04</td>\n      <td>1790.30</td>\n      <td>0.68</td>\n      <td>1790.34</td>\n      <td>0.08</td>\n      <td>1790.28</td>\n      <td>...</td>\n      <td>1790.43</td>\n      <td>0.02</td>\n      <td>1790.21</td>\n      <td>0.02</td>\n      <td>1790.45</td>\n      <td>0.04</td>\n      <td>1790.20</td>\n      <td>1.12</td>\n      <td>1790.47</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1745798401</td>\n      <td>1790.31</td>\n      <td>38.71</td>\n      <td>1790.32</td>\n      <td>14.93</td>\n      <td>1790.30</td>\n      <td>0.68</td>\n      <td>1790.34</td>\n      <td>0.08</td>\n      <td>1790.28</td>\n      <td>...</td>\n      <td>1790.43</td>\n      <td>0.02</td>\n      <td>1790.21</td>\n      <td>0.02</td>\n      <td>1790.45</td>\n      <td>0.04</td>\n      <td>1790.20</td>\n      <td>1.12</td>\n      <td>1790.47</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1745798402</td>\n      <td>1790.31</td>\n      <td>18.98</td>\n      <td>1790.32</td>\n      <td>27.39</td>\n      <td>1790.28</td>\n      <td>0.02</td>\n      <td>1790.33</td>\n      <td>0.03</td>\n      <td>1790.26</td>\n      <td>...</td>\n      <td>1790.41</td>\n      <td>1.00</td>\n      <td>1790.20</td>\n      <td>1.12</td>\n      <td>1790.43</td>\n      <td>0.02</td>\n      <td>1790.19</td>\n      <td>0.16</td>\n      <td>1790.45</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1745798403</td>\n      <td>1790.31</td>\n      <td>27.70</td>\n      <td>1790.32</td>\n      <td>9.89</td>\n      <td>1790.28</td>\n      <td>0.02</td>\n      <td>1790.34</td>\n      <td>0.08</td>\n      <td>1790.26</td>\n      <td>...</td>\n      <td>1790.43</td>\n      <td>0.02</td>\n      <td>1790.20</td>\n      <td>1.12</td>\n      <td>1790.45</td>\n      <td>0.02</td>\n      <td>1790.19</td>\n      <td>0.16</td>\n      <td>1790.47</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1745798404</td>\n      <td>1790.31</td>\n      <td>27.58</td>\n      <td>1790.32</td>\n      <td>10.34</td>\n      <td>1790.28</td>\n      <td>0.02</td>\n      <td>1790.34</td>\n      <td>0.08</td>\n      <td>1790.26</td>\n      <td>...</td>\n      <td>1790.43</td>\n      <td>0.02</td>\n      <td>1790.20</td>\n      <td>1.12</td>\n      <td>1790.45</td>\n      <td>0.02</td>\n      <td>1790.19</td>\n      <td>0.16</td>\n      <td>1790.47</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>863996</th>\n      <td>1746662396</td>\n      <td>1810.48</td>\n      <td>52.96</td>\n      <td>1810.49</td>\n      <td>62.14</td>\n      <td>1810.47</td>\n      <td>1.53</td>\n      <td>1810.50</td>\n      <td>0.01</td>\n      <td>1810.45</td>\n      <td>...</td>\n      <td>1810.58</td>\n      <td>5.06</td>\n      <td>1810.36</td>\n      <td>0.02</td>\n      <td>1810.59</td>\n      <td>16.34</td>\n      <td>1810.35</td>\n      <td>6.29</td>\n      <td>1810.60</td>\n      <td>1.97</td>\n    </tr>\n    <tr>\n      <th>863997</th>\n      <td>1746662397</td>\n      <td>1810.48</td>\n      <td>6.68</td>\n      <td>1810.49</td>\n      <td>74.63</td>\n      <td>1810.47</td>\n      <td>0.02</td>\n      <td>1810.50</td>\n      <td>0.01</td>\n      <td>1810.45</td>\n      <td>...</td>\n      <td>1810.59</td>\n      <td>16.34</td>\n      <td>1810.36</td>\n      <td>0.02</td>\n      <td>1810.60</td>\n      <td>1.97</td>\n      <td>1810.35</td>\n      <td>6.29</td>\n      <td>1810.61</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>863998</th>\n      <td>1746662398</td>\n      <td>1810.48</td>\n      <td>19.02</td>\n      <td>1810.49</td>\n      <td>55.80</td>\n      <td>1810.46</td>\n      <td>0.02</td>\n      <td>1810.50</td>\n      <td>0.01</td>\n      <td>1810.45</td>\n      <td>...</td>\n      <td>1810.59</td>\n      <td>16.34</td>\n      <td>1810.36</td>\n      <td>8.30</td>\n      <td>1810.60</td>\n      <td>1.97</td>\n      <td>1810.35</td>\n      <td>6.29</td>\n      <td>1810.61</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>863999</th>\n      <td>1746662399</td>\n      <td>1810.26</td>\n      <td>4.74</td>\n      <td>1810.27</td>\n      <td>93.51</td>\n      <td>1810.25</td>\n      <td>0.02</td>\n      <td>1810.30</td>\n      <td>2.95</td>\n      <td>1810.24</td>\n      <td>...</td>\n      <td>1810.38</td>\n      <td>0.01</td>\n      <td>1810.13</td>\n      <td>3.87</td>\n      <td>1810.40</td>\n      <td>1.97</td>\n      <td>1810.12</td>\n      <td>0.17</td>\n      <td>1810.41</td>\n      <td>0.30</td>\n    </tr>\n    <tr>\n      <th>864000</th>\n      <td>1746662400</td>\n      <td>1810.26</td>\n      <td>7.95</td>\n      <td>1810.27</td>\n      <td>100.01</td>\n      <td>1810.25</td>\n      <td>0.02</td>\n      <td>1810.29</td>\n      <td>3.18</td>\n      <td>1810.24</td>\n      <td>...</td>\n      <td>1810.36</td>\n      <td>10.91</td>\n      <td>1810.13</td>\n      <td>0.03</td>\n      <td>1810.37</td>\n      <td>23.04</td>\n      <td>1810.12</td>\n      <td>0.17</td>\n      <td>1810.38</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>864001 rows × 41 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df = df.sort_values(by=['timestamp']).reset_index(drop=True)","metadata":{"id":"niosxNvYBrSA","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:27.802459Z","iopub.execute_input":"2025-05-25T16:43:27.802803Z","iopub.status.idle":"2025-05-25T16:43:28.100454Z","shell.execute_reply.started":"2025-05-25T16:43:27.802776Z","shell.execute_reply":"2025-05-25T16:43:28.098822Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df['date'] = pd.to_datetime(df['timestamp'], unit='s')\ndf['date'] = df['date'].dt.date\ndf['date'] = df['date'].apply(lambda x: str(x))","metadata":{"id":"tC3ZytlnBrUW","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:28.102232Z","iopub.execute_input":"2025-05-25T16:43:28.102751Z","iopub.status.idle":"2025-05-25T16:43:29.221743Z","shell.execute_reply.started":"2025-05-25T16:43:28.102685Z","shell.execute_reply":"2025-05-25T16:43:29.220610Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df = df[df['date'] != '2025-05-08'].reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:29.223146Z","iopub.execute_input":"2025-05-25T16:43:29.223392Z","iopub.status.idle":"2025-05-25T16:43:29.619755Z","shell.execute_reply.started":"2025-05-25T16:43:29.223373Z","shell.execute_reply":"2025-05-25T16:43:29.618343Z"},"id":"N-OCzObcvXas"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"numeric_columns = [col for col in df.columns if col not in ['timestamp', 'date']]","metadata":{"id":"sSDmlKqgBrWe","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:29.620896Z","iopub.execute_input":"2025-05-25T16:43:29.621168Z","iopub.status.idle":"2025-05-25T16:43:29.627373Z","shell.execute_reply.started":"2025-05-25T16:43:29.621145Z","shell.execute_reply":"2025-05-25T16:43:29.626290Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"dates_str_list = list(df['date'].unique())","metadata":{"id":"eM7oFm8KBrao","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:29.629189Z","iopub.execute_input":"2025-05-25T16:43:29.629647Z","iopub.status.idle":"2025-05-25T16:43:29.715804Z","shell.execute_reply.started":"2025-05-25T16:43:29.629617Z","shell.execute_reply":"2025-05-25T16:43:29.714420Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"daily_data_dict = {}","metadata":{"id":"9Vp7Z5luBrct","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:29.716871Z","iopub.execute_input":"2025-05-25T16:43:29.717294Z","iopub.status.idle":"2025-05-25T16:43:29.722828Z","shell.execute_reply.started":"2025-05-25T16:43:29.717257Z","shell.execute_reply":"2025-05-25T16:43:29.721531Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"for i in range(len(dates_str_list)):\n    date = dates_str_list[i]\n    if date not in daily_data_dict.keys():\n        daily_data_dict[date] = np.array(df[df['date']==dates_str_list[i]][numeric_columns])","metadata":{"id":"wVkdhDarBre2","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:29.723966Z","iopub.execute_input":"2025-05-25T16:43:29.724327Z","iopub.status.idle":"2025-05-25T16:43:30.786009Z","shell.execute_reply.started":"2025-05-25T16:43:29.724295Z","shell.execute_reply":"2025-05-25T16:43:30.784138Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"mid_price_changes = compute_mid_price_changes(daily_data_dict, ['2025-04-28'], 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.787182Z","iopub.execute_input":"2025-05-25T16:43:30.787567Z","iopub.status.idle":"2025-05-25T16:43:30.820377Z","shell.execute_reply.started":"2025-05-25T16:43:30.787459Z","shell.execute_reply":"2025-05-25T16:43:30.819272Z"},"id":"m8q-oMIKvXa1"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"alpha = np.quantile(mid_price_changes, 0.3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.821581Z","iopub.execute_input":"2025-05-25T16:43:30.821921Z","iopub.status.idle":"2025-05-25T16:43:30.833135Z","shell.execute_reply.started":"2025-05-25T16:43:30.821884Z","shell.execute_reply":"2025-05-25T16:43:30.831329Z"},"id":"epmdt5uHvXa2"},"outputs":[],"execution_count":18},{"cell_type":"code","source":"alpha","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.834645Z","iopub.execute_input":"2025-05-25T16:43:30.835010Z","iopub.status.idle":"2025-05-25T16:43:30.859182Z","shell.execute_reply.started":"2025-05-25T16:43:30.834979Z","shell.execute_reply":"2025-05-25T16:43:30.857816Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq5k6RfjvXbF","outputId":"98e75881-bdb4-47d6-e507-e338239946e1"},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"-6.495761631192181e-05"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"daily_data_dict.pop('2025-04-28')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.860944Z","iopub.execute_input":"2025-05-25T16:43:30.861280Z","iopub.status.idle":"2025-05-25T16:43:30.890289Z","shell.execute_reply.started":"2025-05-25T16:43:30.861248Z","shell.execute_reply":"2025-05-25T16:43:30.888512Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"JZqNwpXGvXbG","outputId":"1b06723c-b430-4cfd-b384-e18d1cb0b6c8"},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([[1.79031e+03, 3.85900e+01, 1.79032e+03, ..., 1.12000e+00,\n        1.79047e+03, 2.00000e-02],\n       [1.79031e+03, 3.87100e+01, 1.79032e+03, ..., 1.12000e+00,\n        1.79047e+03, 2.00000e-02],\n       [1.79031e+03, 1.89800e+01, 1.79032e+03, ..., 1.60000e-01,\n        1.79045e+03, 2.00000e-02],\n       ...,\n       [1.79890e+03, 1.36890e+02, 1.79891e+03, ..., 2.00000e-02,\n        1.79901e+03, 2.00000e-02],\n       [1.79890e+03, 1.39910e+02, 1.79891e+03, ..., 2.00000e-02,\n        1.79901e+03, 2.00000e-02],\n       [1.79890e+03, 1.38780e+02, 1.79891e+03, ..., 2.00000e-02,\n        1.79901e+03, 2.00000e-02]])"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"dates_str_list = dates_str_list[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.891291Z","iopub.execute_input":"2025-05-25T16:43:30.891742Z","iopub.status.idle":"2025-05-25T16:43:30.915995Z","shell.execute_reply.started":"2025-05-25T16:43:30.891675Z","shell.execute_reply":"2025-05-25T16:43:30.914337Z"},"id":"njB6dKH6vXbG"},"outputs":[],"execution_count":21},{"cell_type":"code","source":"normalization_mean_dict = {}\nnormalization_stddev_dict = {}","metadata":{"id":"qhMYFum4Brha","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.917530Z","iopub.execute_input":"2025-05-25T16:43:30.918233Z","iopub.status.idle":"2025-05-25T16:43:30.941959Z","shell.execute_reply.started":"2025-05-25T16:43:30.918193Z","shell.execute_reply":"2025-05-25T16:43:30.940468Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"for i in range(5,len(dates_str_list)):\n    date = dates_str_list[i]\n\n    if (date not in normalization_mean_dict.keys()) or (date not in normalization_stddev_dict.keys()):\n        look_back_dates_list = dates_str_list[(i-5):i]\n        prev_5_day_orderbook_np = None\n        for look_back_date in look_back_dates_list:\n            if prev_5_day_orderbook_np is None:\n                prev_5_day_orderbook_np = daily_data_dict[look_back_date]\n            else:\n                prev_5_day_orderbook_np = np.vstack((prev_5_day_orderbook_np, daily_data_dict[look_back_date]))\n\n\n        price_mean = prev_5_day_orderbook_np[:,range(0,prev_5_day_orderbook_np.shape[1],2)].mean()\n        price_std = prev_5_day_orderbook_np[:,range(0,prev_5_day_orderbook_np.shape[1],2)].std()\n        size_mean = prev_5_day_orderbook_np[:,range(1,prev_5_day_orderbook_np.shape[1],2)].mean()\n        size_std = prev_5_day_orderbook_np[:,range(1,prev_5_day_orderbook_np.shape[1],2)].std()\n\n        normalization_mean_dict[date] = np.repeat([[price_mean,size_mean]], 20, axis=0).flatten()\n        normalization_stddev_dict[date] = np.repeat([[price_std,size_std]], 20, axis=0).flatten()","metadata":{"id":"quOEQtkAEFbH","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:30.943419Z","iopub.execute_input":"2025-05-25T16:43:30.943855Z","iopub.status.idle":"2025-05-25T16:43:32.305141Z","shell.execute_reply.started":"2025-05-25T16:43:30.943830Z","shell.execute_reply":"2025-05-25T16:43:32.303794Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"daily_norm_data_dict = {}","metadata":{"id":"_-vXUHuFEWNK","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.306725Z","iopub.execute_input":"2025-05-25T16:43:32.307085Z","iopub.status.idle":"2025-05-25T16:43:32.312834Z","shell.execute_reply.started":"2025-05-25T16:43:32.307059Z","shell.execute_reply":"2025-05-25T16:43:32.311965Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"daily_norm_data_dict = {}\nfor i in range(5, len(dates_str_list)):\n    date = dates_str_list[i]\n    if date not in daily_norm_data_dict.keys():\n        raw_data = daily_data_dict[date]\n\n        # Шаг 1: Нормализация базовых 40 признаков\n        norm_data = (raw_data - normalization_mean_dict[date]) / normalization_stddev_dict[date]\n\n        # Шаг 2: Feature engineering — доп. признаки\n\n        # Mid-price = (ask_price_1 + bid_price_1) / 2\n        mid_price = ((raw_data[:, 2] + raw_data[:, 0]) / 2).reshape(-1, 1)\n\n        # Spread = ask_price_1 - bid_price_1\n        spread = (raw_data[:, 2] - raw_data[:, 0]).reshape(-1, 1)\n\n        # Imbalance = (bid_depth - ask_depth) / (bid_depth + ask_depth)\n        bid_depth = raw_data[:, [i for i in range(1, 40, 4)]].sum(axis=1)\n        ask_depth = raw_data[:, [i for i in range(3, 40, 4)]].sum(axis=1)\n        imbalance = ((bid_depth - ask_depth) / (bid_depth + ask_depth + 1e-8)).reshape(-1, 1)\n\n        # Объединяем все признаки в один массив\n        full_data = np.hstack([norm_data, mid_price, spread, imbalance])\n\n        daily_norm_data_dict[date] = full_data","metadata":{"id":"Kehzuw2SxnTG","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.313784Z","iopub.execute_input":"2025-05-25T16:43:32.314067Z","iopub.status.idle":"2025-05-25T16:43:32.488541Z","shell.execute_reply.started":"2025-05-25T16:43:32.314044Z","shell.execute_reply":"2025-05-25T16:43:32.487738Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"list(daily_data_dict.keys())[5:]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIdBwSvBzD9-","outputId":"9406981a-ae09-451c-afca-5b732c00bdae","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.489756Z","iopub.execute_input":"2025-05-25T16:43:32.490197Z","iopub.status.idle":"2025-05-25T16:43:32.498445Z","shell.execute_reply.started":"2025-05-25T16:43:32.490094Z","shell.execute_reply":"2025-05-25T16:43:32.496783Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['2025-05-04', '2025-05-05', '2025-05-06', '2025-05-07']"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def generate_labels(k, alpha, daily_data_dict):\n    daily_label_dict = {}\n    for date in list(daily_data_dict.keys())[5:]:\n        price_bid = daily_data_dict[date][:,0]\n        size_bid = daily_data_dict[date][:,1]\n        price_ask = daily_data_dict[date][:,2]\n        size_ask = daily_data_dict[date][:,3]\n        mid_price = (price_ask * size_bid + price_bid * size_ask) / (size_ask + size_bid)\n        future_k_avg_mid_price = moving_average(mid_price, k)[1:]\n        print(future_k_avg_mid_price.shape, mid_price[:-k].shape)\n        change_pct = (future_k_avg_mid_price - mid_price[:-k])/mid_price[:-k]\n        print(change_pct, len(change_pct))\n        y_label = (-(change_pct < -alpha).astype(int)) + (change_pct > alpha).astype(int)\n\n        daily_label_dict[date] = y_label.reshape(-1,1)\n    return daily_label_dict","metadata":{"id":"Bmq4V4tKpF-p","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.500536Z","iopub.execute_input":"2025-05-25T16:43:32.501345Z","iopub.status.idle":"2025-05-25T16:43:32.521531Z","shell.execute_reply.started":"2025-05-25T16:43:32.501315Z","shell.execute_reply":"2025-05-25T16:43:32.520318Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def generate_X_y(k, alpha, timestamp_per_sample, daily_norm_data_dict, daily_data_dict):\n    #k is the number of future timesteps used to generate the label y\n    data_x = None\n    for date in daily_norm_data_dict.keys():\n        if data_x is None:\n            data_x = daily_norm_data_dict[date].copy()[:-k,:]\n        else:\n            data_x = np.vstack((data_x, daily_norm_data_dict[date][:-k,:]))\n\n    daily_label_dict = generate_labels(k, alpha, daily_data_dict)\n    data_y = None\n    for date in daily_label_dict.keys():\n        if data_y is None:\n            data_y = daily_label_dict[date].copy()\n        else:\n            data_y = np.vstack((data_y, daily_label_dict[date]))\n\n    [N, P_x] = data_x.shape\n\n    x = np.zeros([(N-timestamp_per_sample+1), timestamp_per_sample, P_x])\n\n    for i in range(N-timestamp_per_sample+1):\n        x[i] = data_x[i:(i+timestamp_per_sample), :]\n\n    x = x.reshape(x.shape + (1,))\n    y = data_y[(timestamp_per_sample-1):]\n    y = to_categorical(y, 3)\n\n    return x, y","metadata":{"id":"-g41Y0MVpeaX","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.526398Z","iopub.execute_input":"2025-05-25T16:43:32.526729Z","iopub.status.idle":"2025-05-25T16:43:32.550088Z","shell.execute_reply.started":"2025-05-25T16:43:32.526672Z","shell.execute_reply":"2025-05-25T16:43:32.549009Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"daily_norm_data_dict.pop('2025-05-07')\ndaily_data_dict.pop('2025-05-07')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.551021Z","iopub.execute_input":"2025-05-25T16:43:32.551377Z","iopub.status.idle":"2025-05-25T16:43:32.575246Z","shell.execute_reply.started":"2025-05-25T16:43:32.551341Z","shell.execute_reply":"2025-05-25T16:43:32.573467Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"C-D_MtzrvXbZ","outputId":"d44602c7-746b-48f7-c711-ab9be8d160e7"},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"array([[1.81636e+03, 5.87400e+01, 1.81637e+03, ..., 4.00000e-02,\n        1.81650e+03, 1.97400e+01],\n       [1.81679e+03, 1.34600e+01, 1.81680e+03, ..., 4.60000e-01,\n        1.81692e+03, 3.36000e+00],\n       [1.81681e+03, 2.49000e+00, 1.81682e+03, ..., 2.00000e-02,\n        1.81693e+03, 3.40000e-01],\n       ...,\n       [1.81048e+03, 6.68000e+00, 1.81049e+03, ..., 6.29000e+00,\n        1.81061e+03, 3.00000e-02],\n       [1.81048e+03, 1.90200e+01, 1.81049e+03, ..., 6.29000e+00,\n        1.81061e+03, 3.00000e-02],\n       [1.81026e+03, 4.74000e+00, 1.81027e+03, ..., 1.70000e-01,\n        1.81041e+03, 3.00000e-01]])"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"X,y = generate_X_y(k=8, alpha=alpha, timestamp_per_sample=100,\n                   daily_norm_data_dict= daily_norm_data_dict,\n                   daily_data_dict = daily_data_dict)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zw9x3vFLqm5W","outputId":"35a718b8-e3f8-4477-a48f-96c439d4fbb9","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:32.576301Z","iopub.execute_input":"2025-05-25T16:43:32.576850Z","iopub.status.idle":"2025-05-25T16:43:43.175658Z","shell.execute_reply.started":"2025-05-25T16:43:32.576813Z","shell.execute_reply":"2025-05-25T16:43:43.174782Z"}},"outputs":[{"name":"stdout","text":"(86392,) (86392,)\n[ 5.57455492e-05  1.01256770e-05  1.72004573e-05 ... -4.25251081e-05\n -4.80992974e-05 -5.47959905e-05] 86392\n(86392,) (86392,)\n[-1.89716698e-04 -2.51378867e-04 -3.24225802e-04 ...  3.04242716e-05\n -5.76103946e-08  1.98654638e-06] 86392\n(86392,) (86392,)\n[ 1.94291057e-04 -1.46386669e-06 -2.07872586e-05 ...  6.15573640e-05\n  8.43943060e-05  1.04291292e-04] 86392\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"del daily_norm_data_dict\ndel daily_data_dict\ndel dates_str_list\ndel normalization_mean_dict\ndel normalization_stddev_dict\ndel df\nimport gc; gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8N1rjpSDGpE","outputId":"b9b246d4-cf70-462c-9f80-5eeac743e33b","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:43.176580Z","iopub.execute_input":"2025-05-25T16:43:43.176840Z","iopub.status.idle":"2025-05-25T16:43:43.494101Z","shell.execute_reply.started":"2025-05-25T16:43:43.176819Z","shell.execute_reply":"2025-05-25T16:43:43.492036Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"y[:, 0].sum(), y[:, 1].sum(), y[:, 2].sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYpXXqgaveT5","outputId":"0bc4ad00-aab8-4598-a15b-8ba48acd98f0","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:43.495363Z","iopub.execute_input":"2025-05-25T16:43:43.495725Z","iopub.status.idle":"2025-05-25T16:43:43.529961Z","shell.execute_reply.started":"2025-05-25T16:43:43.495670Z","shell.execute_reply":"2025-05-25T16:43:43.527880Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(137151.0, 61099.0, 60827.0)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=SEED,\n    shuffle=False\n)","metadata":{"id":"OlscV952xcRQ","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:43:43.531239Z","iopub.execute_input":"2025-05-25T16:43:43.531946Z","iopub.status.idle":"2025-05-25T16:43:47.692355Z","shell.execute_reply.started":"2025-05-25T16:43:43.531893Z","shell.execute_reply":"2025-05-25T16:43:47.691172Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"lookback_timestep = 100\nfeature_num = 43\n\n#Conv param\nconv_filter_num = 16\n\n#Inception module param\ninception_num = 32\n\n#LSTM param\nLSTM_num = 64\n\n#Activation param\nleaky_relu_alpha = 0.01\n\n# ADAM is used\nlearning_rate = 1e-3\nadam_epsilon = 1e-7\noptimizer = Adam(learning_rate=learning_rate, epsilon=adam_epsilon)\n\n# accuracy is used for stopping training\nmetrics = ['accuracy']\n\nnum_epoch = 100\n#stop training when validation accuracy does not improve for 20 epochs\nstop_epoch_num = 50\n\nbatch_size = 256","metadata":{"id":"SM24pG0JxcTh","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:07:22.757380Z","iopub.execute_input":"2025-05-23T07:07:22.758067Z","iopub.status.idle":"2025-05-23T07:07:25.274105Z","shell.execute_reply.started":"2025-05-23T07:07:22.758040Z","shell.execute_reply":"2025-05-23T07:07:25.273303Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1747984045.223134      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1747984045.223781      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"@register_keras_serializable()\ndef focal_loss(gamma=2., alpha=0.25):\n    def loss(y_true, y_pred):\n        y_pred = K.clip(y_pred, 1e-8, 1. - 1e-8)\n        cross_entropy = -y_true * K.log(y_pred)\n        weight = alpha * K.pow(1 - y_pred, gamma)\n        loss = weight * cross_entropy\n        return K.mean(K.sum(loss, axis=1))\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:22:22.369397Z","iopub.execute_input":"2025-05-23T09:22:22.370053Z","iopub.status.idle":"2025-05-23T09:22:22.374358Z","shell.execute_reply.started":"2025-05-23T09:22:22.370030Z","shell.execute_reply":"2025-05-23T09:22:22.373551Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def initiate_DeepLOB_modified_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n                        optimizer, metrics):\n\n    input_tensor = Input(shape=(lookback_timestep, feature_num, 1))\n    print(\"Input tensor shape:\", input_tensor.shape)\n\n    # --- Conv Block 1 ---\n    conv_layer1 = Conv2D(conv_filter_num, (1, 2), strides=(1, 2))(input_tensor)\n    print(\"Conv1-1 (1x2) shape:\", conv_layer1.shape)\n\n    conv_layer1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n    print(\"Conv1-1 after LeakyReLU:\", conv_layer1.shape)\n\n    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n    print(\"Conv1-2 (4x1) shape:\", conv_layer1.shape)\n\n    conv_layer1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n\n    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n    print(\"Conv1-3 (4x1) shape:\", conv_layer1.shape)\n\n    conv_layer1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n\n    # --- Conv Block 2 ---\n    conv_layer2 = Conv2D(conv_filter_num, (1,2), strides=(1, 2))(conv_layer1)\n    print(\"Conv2-1 (1x2) shape:\", conv_layer2.shape)\n\n    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n\n    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n    print(\"Conv2-2 (4x1) shape:\", conv_layer2.shape)\n\n    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n\n    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n    print(\"Conv2-3 (4x1) shape:\", conv_layer2.shape)\n\n    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n\n    # --- Conv Block 3 ---\n    conv_layer3 = Conv2D(conv_filter_num, (1,10))(conv_layer2)\n    print(\"Conv3-1 (1x10) shape:\", conv_layer3.shape)\n\n    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n\n    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n    print(\"Conv3-2 (4x1) shape:\", conv_layer3.shape)\n\n    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n\n    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n    print(\"Conv3-3 (4x1) shape:\", conv_layer3.shape)\n\n    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n\n    # --- Inception Module ---\n    inception_module1 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n    print(\"Inception branch 1 - after 1x1 LeakyReLU:\", inception_module1.shape)\n\n    inception_module1 = Conv2D(inception_num, (3,1), padding='same')(inception_module1)\n    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n    print(\"Inception branch 1 - after 3x1:\", inception_module1.shape)\n\n    inception_module2 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n    print(\"Inception branch 2 - after 1x1 LeakyReLU:\", inception_module2.shape)\n\n    inception_module2 = Conv2D(inception_num, (5,1), padding='same')(inception_module2)\n    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n    print(\"Inception branch 2 - after 5x1:\", inception_module2.shape)\n\n    inception_module3 = MaxPooling2D((3,1), strides=(1,1), padding='same')(conv_layer3)\n    print(\"Inception branch 3 - after MaxPooling:\", inception_module3.shape)\n\n    inception_module3 = Conv2D(inception_num, (1,1), padding='same')(inception_module3)\n    print(\"Inception branch 3 - after 1x1 conv:\", inception_module3.shape)\n\n    inception_module3 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module3)\n    print(\"Inception branch 3 - after LeakyReLU:\", inception_module3.shape)\n\n    # Объединяем\n    inception_module_final = concatenate([inception_module1, inception_module2, inception_module3], axis=3)\n    print(\"After concatenation:\", inception_module_final.shape)\n\n    # Преобразуем для LSTM или Attention\n    inception_module_final = Reshape((inception_module_final.shape[1], inception_module_final.shape[3]))(inception_module_final)\n    print(\"After reshape:\", inception_module_final.shape)\n\n    # Bidirectional LSTM\n    lstm_out = Bidirectional(LSTM(LSTM_num, return_sequences=True))(inception_module_final)\n    print(\"Bidirectional LSTM:\", lstm_out.shape)\n\n    # Attention слой (self-attention по временной оси)\n    attention_scores = Dense(1, activation='tanh')(lstm_out)\n    attention_weights = Softmax(axis=1)(attention_scores)\n    print(\"Attention weights:\", attention_weights.shape)\n    @register_keras_serializable()\n    def attention_context(x):\n        return tf.reduce_sum(x[0] * x[1], axis=1)\n    \n    @register_keras_serializable()\n    def attention_output_shape(input_shapes):\n        return (input_shapes[0][0], input_shapes[0][2])\n    \n    context = Lambda(attention_context, output_shape=attention_output_shape)([lstm_out, attention_weights])\n\n    print(\"Context vector:\", context.shape)\n\n    # Fully Connected Layer with softmax activation function for output\n    model_output = Dense(3, activation='softmax')(context)\n    print(model_output.shape)\n\n    DeepLOB_modified_model = Model(inputs=input_tensor, outputs= model_output)\n    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1)\n\n    DeepLOB_modified_model.compile(optimizer=optimizer, loss=focal_loss(), metrics=metrics)\n\n    return DeepLOB_modified_model","metadata":{"id":"l_3lzzlkxcWP","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:07:25.287351Z","iopub.execute_input":"2025-05-23T07:07:25.287658Z","iopub.status.idle":"2025-05-23T07:07:25.306585Z","shell.execute_reply.started":"2025-05-23T07:07:25.287641Z","shell.execute_reply":"2025-05-23T07:07:25.306027Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"DeepLOB_modified_model = initiate_DeepLOB_modified_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n                             optimizer, metrics)","metadata":{"id":"Yp5Rx3DaxcYq","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:07:25.307202Z","iopub.execute_input":"2025-05-23T07:07:25.307473Z","iopub.status.idle":"2025-05-23T07:07:27.386693Z","shell.execute_reply.started":"2025-05-23T07:07:25.307458Z","shell.execute_reply":"2025-05-23T07:07:27.385835Z"},"outputId":"37dcf258-ba52-47e2-b5ad-2bebd0c222c4"},"outputs":[{"name":"stdout","text":"Input tensor shape: (None, 100, 43, 1)\nConv1-1 (1x2) shape: (None, 100, 21, 16)\nConv1-1 after LeakyReLU: (None, 100, 21, 16)\nConv1-2 (4x1) shape: (None, 100, 21, 16)\nConv1-3 (4x1) shape: (None, 100, 21, 16)\nConv2-1 (1x2) shape: (None, 100, 10, 16)\nConv2-2 (4x1) shape: (None, 100, 10, 16)\nConv2-3 (4x1) shape: (None, 100, 10, 16)\nConv3-1 (1x10) shape: (None, 100, 1, 16)\nConv3-2 (4x1) shape: (None, 100, 1, 16)\nConv3-3 (4x1) shape: (None, 100, 1, 16)\nInception branch 1 - after 1x1 LeakyReLU: (None, 100, 1, 32)\nInception branch 1 - after 3x1: (None, 100, 1, 32)\nInception branch 2 - after 1x1 LeakyReLU: (None, 100, 1, 32)\nInception branch 2 - after 5x1: (None, 100, 1, 32)\nInception branch 3 - after MaxPooling: (None, 100, 1, 16)\nInception branch 3 - after 1x1 conv: (None, 100, 1, 32)\nInception branch 3 - after LeakyReLU: (None, 100, 1, 32)\nAfter concatenation: (None, 100, 1, 96)\nAfter reshape: (None, 100, 96)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Bidirectional LSTM: (None, 100, 128)\nAttention weights: (None, 100, 1)\nContext vector: (None, 128)\n(None, 3)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"y_train_labels = np.argmax(y_train, axis=1)\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\nclass_weight_dict = dict(enumerate(class_weights))","metadata":{"id":"oIgKK9f65C7-","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:07:27.387610Z","iopub.execute_input":"2025-05-23T07:07:27.387853Z","iopub.status.idle":"2025-05-23T07:07:27.421755Z","shell.execute_reply.started":"2025-05-23T07:07:27.387835Z","shell.execute_reply":"2025-05-23T07:07:27.420893Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"checkpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)  \ncheckpoint_path = os.path.join(checkpoint_dir, 'best_model_v4.keras')\n\n\nmodel_checkpoint = ModelCheckpoint(\n    filepath=checkpoint_path,\n    monitor='val_accuracy',\n    save_best_only=True,\n    save_weights_only=False,\n    verbose=1\n)\n\n\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    mode='max',\n    patience=stop_epoch_num,\n    restore_best_weights=True,\n    verbose=1\n)\n\ncsv_logger = CSVLogger('training_log.csv')","metadata":{"id":"IOxEof7AxcbT","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T07:07:27.422668Z","iopub.execute_input":"2025-05-23T07:07:27.422999Z","iopub.status.idle":"2025-05-23T07:07:27.427788Z","shell.execute_reply.started":"2025-05-23T07:07:27.422979Z","shell.execute_reply":"2025-05-23T07:07:27.427226Z"},"outputId":"4dda0e34-0625-4c7d-90ba-d4f2f7bafada"},"outputs":[],"execution_count":39},{"cell_type":"code","source":"DeepLOB_modified_model.fit(\n    X_train, y_train,\n    epochs=num_epoch,\n    batch_size=batch_size,\n    validation_data=(X_test, y_test),\n    callbacks=[early_stopping, model_checkpoint, csv_logger],\n    class_weight=class_weight_dict,\n    verbose=2\n)","metadata":{"trusted":true,"id":"md6f4OuDvXb3","execution":{"iopub.status.busy":"2025-05-23T07:07:27.428636Z","iopub.execute_input":"2025-05-23T07:07:27.428897Z","iopub.status.idle":"2025-05-23T09:16:43.403153Z","shell.execute_reply.started":"2025-05-23T07:07:27.428868Z","shell.execute_reply":"2025-05-23T09:16:43.402546Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2025-05-23 07:07:44.304427: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_16}}\nI0000 00:00:1747984073.313524     111 cuda_dnn.cc:529] Loaded cuDNN version 90300\n2025-05-23 07:09:06.906033: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_15}}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.53530, saving model to checkpoints/best_model_v4.keras\n810/810 - 91s - 112ms/step - accuracy: 0.5293 - loss: 0.1101 - val_accuracy: 0.5353 - val_loss: 0.1079\nEpoch 2/100\n\nEpoch 2: val_accuracy improved from 0.53530 to 0.54051, saving model to checkpoints/best_model_v4.keras\n810/810 - 76s - 94ms/step - accuracy: 0.5363 - loss: 0.1076 - val_accuracy: 0.5405 - val_loss: 0.1069\nEpoch 3/100\n\nEpoch 3: val_accuracy improved from 0.54051 to 0.54089, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.5391 - loss: 0.1070 - val_accuracy: 0.5409 - val_loss: 0.1061\nEpoch 4/100\n\nEpoch 4: val_accuracy improved from 0.54089 to 0.54796, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5474 - loss: 0.1020 - val_accuracy: 0.5480 - val_loss: 0.1007\nEpoch 5/100\n\nEpoch 5: val_accuracy improved from 0.54796 to 0.55218, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.5517 - loss: 0.1005 - val_accuracy: 0.5522 - val_loss: 0.1001\nEpoch 6/100\n\nEpoch 6: val_accuracy did not improve from 0.55218\n810/810 - 77s - 95ms/step - accuracy: 0.5533 - loss: 0.1000 - val_accuracy: 0.5521 - val_loss: 0.1000\nEpoch 7/100\n\nEpoch 7: val_accuracy did not improve from 0.55218\n810/810 - 77s - 95ms/step - accuracy: 0.5543 - loss: 0.0996 - val_accuracy: 0.5515 - val_loss: 0.0999\nEpoch 8/100\n\nEpoch 8: val_accuracy improved from 0.55218 to 0.55298, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5562 - loss: 0.0992 - val_accuracy: 0.5530 - val_loss: 0.0999\nEpoch 9/100\n\nEpoch 9: val_accuracy did not improve from 0.55298\n810/810 - 77s - 95ms/step - accuracy: 0.5579 - loss: 0.0987 - val_accuracy: 0.5527 - val_loss: 0.0998\nEpoch 10/100\n\nEpoch 10: val_accuracy did not improve from 0.55298\n810/810 - 77s - 95ms/step - accuracy: 0.5598 - loss: 0.0982 - val_accuracy: 0.5514 - val_loss: 0.1001\nEpoch 11/100\n\nEpoch 11: val_accuracy improved from 0.55298 to 0.55408, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5599 - loss: 0.0977 - val_accuracy: 0.5541 - val_loss: 0.0998\nEpoch 12/100\n\nEpoch 12: val_accuracy improved from 0.55408 to 0.55799, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5625 - loss: 0.0971 - val_accuracy: 0.5580 - val_loss: 0.0987\nEpoch 13/100\n\nEpoch 13: val_accuracy did not improve from 0.55799\n810/810 - 77s - 95ms/step - accuracy: 0.5631 - loss: 0.0965 - val_accuracy: 0.5558 - val_loss: 0.0989\nEpoch 14/100\n\nEpoch 14: val_accuracy improved from 0.55799 to 0.55890, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.5668 - loss: 0.0958 - val_accuracy: 0.5589 - val_loss: 0.0984\nEpoch 15/100\n\nEpoch 15: val_accuracy did not improve from 0.55890\n810/810 - 77s - 95ms/step - accuracy: 0.5669 - loss: 0.0952 - val_accuracy: 0.5558 - val_loss: 0.0982\nEpoch 16/100\n\nEpoch 16: val_accuracy did not improve from 0.55890\n810/810 - 77s - 95ms/step - accuracy: 0.5701 - loss: 0.0943 - val_accuracy: 0.5581 - val_loss: 0.0980\nEpoch 17/100\n\nEpoch 17: val_accuracy did not improve from 0.55890\n810/810 - 77s - 95ms/step - accuracy: 0.5718 - loss: 0.0936 - val_accuracy: 0.5585 - val_loss: 0.0971\nEpoch 18/100\n\nEpoch 18: val_accuracy improved from 0.55890 to 0.55994, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5740 - loss: 0.0928 - val_accuracy: 0.5599 - val_loss: 0.0974\nEpoch 19/100\n\nEpoch 19: val_accuracy did not improve from 0.55994\n810/810 - 77s - 95ms/step - accuracy: 0.5758 - loss: 0.0921 - val_accuracy: 0.5584 - val_loss: 0.0971\nEpoch 20/100\n\nEpoch 20: val_accuracy did not improve from 0.55994\n810/810 - 77s - 95ms/step - accuracy: 0.5795 - loss: 0.0911 - val_accuracy: 0.5596 - val_loss: 0.0964\nEpoch 21/100\n\nEpoch 21: val_accuracy improved from 0.55994 to 0.56261, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5807 - loss: 0.0903 - val_accuracy: 0.5626 - val_loss: 0.0960\nEpoch 22/100\n\nEpoch 22: val_accuracy improved from 0.56261 to 0.56378, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5830 - loss: 0.0895 - val_accuracy: 0.5638 - val_loss: 0.0951\nEpoch 23/100\n\nEpoch 23: val_accuracy improved from 0.56378 to 0.56567, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5869 - loss: 0.0884 - val_accuracy: 0.5657 - val_loss: 0.0945\nEpoch 24/100\n\nEpoch 24: val_accuracy did not improve from 0.56567\n810/810 - 77s - 95ms/step - accuracy: 0.5901 - loss: 0.0873 - val_accuracy: 0.5628 - val_loss: 0.0943\nEpoch 25/100\n\nEpoch 25: val_accuracy improved from 0.56567 to 0.56708, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5925 - loss: 0.0865 - val_accuracy: 0.5671 - val_loss: 0.0935\nEpoch 26/100\n\nEpoch 26: val_accuracy improved from 0.56708 to 0.57224, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.5959 - loss: 0.0858 - val_accuracy: 0.5722 - val_loss: 0.0930\nEpoch 27/100\n\nEpoch 27: val_accuracy improved from 0.57224 to 0.57552, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.5984 - loss: 0.0848 - val_accuracy: 0.5755 - val_loss: 0.0916\nEpoch 28/100\n\nEpoch 28: val_accuracy improved from 0.57552 to 0.57583, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6025 - loss: 0.0838 - val_accuracy: 0.5758 - val_loss: 0.0915\nEpoch 29/100\n\nEpoch 29: val_accuracy improved from 0.57583 to 0.57621, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6066 - loss: 0.0826 - val_accuracy: 0.5762 - val_loss: 0.0910\nEpoch 30/100\n\nEpoch 30: val_accuracy improved from 0.57621 to 0.57868, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6108 - loss: 0.0814 - val_accuracy: 0.5787 - val_loss: 0.0911\nEpoch 31/100\n\nEpoch 31: val_accuracy improved from 0.57868 to 0.58208, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6138 - loss: 0.0804 - val_accuracy: 0.5821 - val_loss: 0.0905\nEpoch 32/100\n\nEpoch 32: val_accuracy did not improve from 0.58208\n810/810 - 77s - 95ms/step - accuracy: 0.6169 - loss: 0.0797 - val_accuracy: 0.5804 - val_loss: 0.0898\nEpoch 33/100\n\nEpoch 33: val_accuracy did not improve from 0.58208\n810/810 - 77s - 95ms/step - accuracy: 0.6207 - loss: 0.0785 - val_accuracy: 0.5811 - val_loss: 0.0899\nEpoch 34/100\n\nEpoch 34: val_accuracy improved from 0.58208 to 0.58625, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6252 - loss: 0.0775 - val_accuracy: 0.5862 - val_loss: 0.0886\nEpoch 35/100\n\nEpoch 35: val_accuracy improved from 0.58625 to 0.58843, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6276 - loss: 0.0768 - val_accuracy: 0.5884 - val_loss: 0.0886\nEpoch 36/100\n\nEpoch 36: val_accuracy did not improve from 0.58843\n810/810 - 77s - 95ms/step - accuracy: 0.6313 - loss: 0.0759 - val_accuracy: 0.5873 - val_loss: 0.0881\nEpoch 37/100\n\nEpoch 37: val_accuracy improved from 0.58843 to 0.59281, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6350 - loss: 0.0747 - val_accuracy: 0.5928 - val_loss: 0.0883\nEpoch 38/100\n\nEpoch 38: val_accuracy did not improve from 0.59281\n810/810 - 77s - 95ms/step - accuracy: 0.6378 - loss: 0.0743 - val_accuracy: 0.5871 - val_loss: 0.0882\nEpoch 39/100\n\nEpoch 39: val_accuracy did not improve from 0.59281\n810/810 - 77s - 95ms/step - accuracy: 0.6405 - loss: 0.0734 - val_accuracy: 0.5884 - val_loss: 0.0879\nEpoch 40/100\n\nEpoch 40: val_accuracy improved from 0.59281 to 0.59895, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6442 - loss: 0.0725 - val_accuracy: 0.5989 - val_loss: 0.0865\nEpoch 41/100\n\nEpoch 41: val_accuracy did not improve from 0.59895\n810/810 - 77s - 95ms/step - accuracy: 0.6504 - loss: 0.0712 - val_accuracy: 0.5970 - val_loss: 0.0870\nEpoch 42/100\n\nEpoch 42: val_accuracy improved from 0.59895 to 0.60180, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6521 - loss: 0.0707 - val_accuracy: 0.6018 - val_loss: 0.0859\nEpoch 43/100\n\nEpoch 43: val_accuracy improved from 0.60180 to 0.60188, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6542 - loss: 0.0702 - val_accuracy: 0.6019 - val_loss: 0.0863\nEpoch 44/100\n\nEpoch 44: val_accuracy improved from 0.60188 to 0.60371, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6569 - loss: 0.0693 - val_accuracy: 0.6037 - val_loss: 0.0854\nEpoch 45/100\n\nEpoch 45: val_accuracy improved from 0.60371 to 0.61056, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6582 - loss: 0.0690 - val_accuracy: 0.6106 - val_loss: 0.0848\nEpoch 46/100\n\nEpoch 46: val_accuracy did not improve from 0.61056\n810/810 - 77s - 95ms/step - accuracy: 0.6636 - loss: 0.0681 - val_accuracy: 0.6080 - val_loss: 0.0847\nEpoch 47/100\n\nEpoch 47: val_accuracy improved from 0.61056 to 0.61184, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6654 - loss: 0.0677 - val_accuracy: 0.6118 - val_loss: 0.0848\nEpoch 48/100\n\nEpoch 48: val_accuracy improved from 0.61184 to 0.61429, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6695 - loss: 0.0663 - val_accuracy: 0.6143 - val_loss: 0.0833\nEpoch 49/100\n\nEpoch 49: val_accuracy did not improve from 0.61429\n810/810 - 77s - 95ms/step - accuracy: 0.6697 - loss: 0.0666 - val_accuracy: 0.6114 - val_loss: 0.0835\nEpoch 50/100\n\nEpoch 50: val_accuracy did not improve from 0.61429\n810/810 - 77s - 95ms/step - accuracy: 0.6742 - loss: 0.0653 - val_accuracy: 0.6113 - val_loss: 0.0844\nEpoch 51/100\n\nEpoch 51: val_accuracy did not improve from 0.61429\n810/810 - 77s - 95ms/step - accuracy: 0.6769 - loss: 0.0647 - val_accuracy: 0.6066 - val_loss: 0.0853\nEpoch 52/100\n\nEpoch 52: val_accuracy did not improve from 0.61429\n810/810 - 77s - 95ms/step - accuracy: 0.6767 - loss: 0.0646 - val_accuracy: 0.6130 - val_loss: 0.0842\nEpoch 53/100\n\nEpoch 53: val_accuracy improved from 0.61429 to 0.61576, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6825 - loss: 0.0633 - val_accuracy: 0.6158 - val_loss: 0.0833\nEpoch 54/100\n\nEpoch 54: val_accuracy improved from 0.61576 to 0.61657, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6848 - loss: 0.0629 - val_accuracy: 0.6166 - val_loss: 0.0832\nEpoch 55/100\n\nEpoch 55: val_accuracy did not improve from 0.61657\n810/810 - 77s - 95ms/step - accuracy: 0.6855 - loss: 0.0624 - val_accuracy: 0.6130 - val_loss: 0.0849\nEpoch 56/100\n\nEpoch 56: val_accuracy did not improve from 0.61657\n810/810 - 77s - 95ms/step - accuracy: 0.6032 - loss: 0.0846 - val_accuracy: 0.6109 - val_loss: 0.0834\nEpoch 57/100\n\nEpoch 57: val_accuracy improved from 0.61657 to 0.62093, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6802 - loss: 0.0644 - val_accuracy: 0.6209 - val_loss: 0.0819\nEpoch 58/100\n\nEpoch 58: val_accuracy did not improve from 0.62093\n810/810 - 77s - 95ms/step - accuracy: 0.6892 - loss: 0.0619 - val_accuracy: 0.6177 - val_loss: 0.0835\nEpoch 59/100\n\nEpoch 59: val_accuracy improved from 0.62093 to 0.63102, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.6934 - loss: 0.0611 - val_accuracy: 0.6310 - val_loss: 0.0801\nEpoch 60/100\n\nEpoch 60: val_accuracy did not improve from 0.63102\n810/810 - 77s - 95ms/step - accuracy: 0.6958 - loss: 0.0604 - val_accuracy: 0.6299 - val_loss: 0.0805\nEpoch 61/100\n\nEpoch 61: val_accuracy did not improve from 0.63102\n810/810 - 77s - 95ms/step - accuracy: 0.6962 - loss: 0.0602 - val_accuracy: 0.6177 - val_loss: 0.0821\nEpoch 62/100\n\nEpoch 62: val_accuracy did not improve from 0.63102\n810/810 - 77s - 95ms/step - accuracy: 0.6967 - loss: 0.0603 - val_accuracy: 0.6254 - val_loss: 0.0814\nEpoch 63/100\n\nEpoch 63: val_accuracy improved from 0.63102 to 0.63324, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7011 - loss: 0.0590 - val_accuracy: 0.6332 - val_loss: 0.0800\nEpoch 64/100\n\nEpoch 64: val_accuracy did not improve from 0.63324\n810/810 - 77s - 95ms/step - accuracy: 0.7017 - loss: 0.0591 - val_accuracy: 0.6203 - val_loss: 0.0831\nEpoch 65/100\n\nEpoch 65: val_accuracy improved from 0.63324 to 0.63895, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.6878 - loss: 0.0626 - val_accuracy: 0.6390 - val_loss: 0.0784\nEpoch 66/100\n\nEpoch 66: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.7088 - loss: 0.0574 - val_accuracy: 0.6368 - val_loss: 0.0800\nEpoch 67/100\n\nEpoch 67: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.7108 - loss: 0.0570 - val_accuracy: 0.6349 - val_loss: 0.0790\nEpoch 68/100\n\nEpoch 68: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.7114 - loss: 0.0566 - val_accuracy: 0.6355 - val_loss: 0.0801\nEpoch 69/100\n\nEpoch 69: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.7112 - loss: 0.0565 - val_accuracy: 0.6363 - val_loss: 0.0795\nEpoch 70/100\n\nEpoch 70: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.6902 - loss: 0.0626 - val_accuracy: 0.6313 - val_loss: 0.0802\nEpoch 71/100\n\nEpoch 71: val_accuracy did not improve from 0.63895\n810/810 - 77s - 95ms/step - accuracy: 0.7146 - loss: 0.0563 - val_accuracy: 0.6319 - val_loss: 0.0810\nEpoch 72/100\n\nEpoch 72: val_accuracy improved from 0.63895 to 0.63903, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.7194 - loss: 0.0550 - val_accuracy: 0.6390 - val_loss: 0.0792\nEpoch 73/100\n\nEpoch 73: val_accuracy did not improve from 0.63903\n810/810 - 77s - 95ms/step - accuracy: 0.7210 - loss: 0.0547 - val_accuracy: 0.6310 - val_loss: 0.0816\nEpoch 74/100\n\nEpoch 74: val_accuracy did not improve from 0.63903\n810/810 - 77s - 95ms/step - accuracy: 0.7217 - loss: 0.0546 - val_accuracy: 0.6286 - val_loss: 0.0821\nEpoch 75/100\n\nEpoch 75: val_accuracy did not improve from 0.63903\n810/810 - 77s - 95ms/step - accuracy: 0.7234 - loss: 0.0541 - val_accuracy: 0.6300 - val_loss: 0.0821\nEpoch 76/100\n\nEpoch 76: val_accuracy did not improve from 0.63903\n810/810 - 77s - 95ms/step - accuracy: 0.7250 - loss: 0.0535 - val_accuracy: 0.6358 - val_loss: 0.0814\nEpoch 77/100\n\nEpoch 77: val_accuracy did not improve from 0.63903\n810/810 - 77s - 95ms/step - accuracy: 0.7247 - loss: 0.0536 - val_accuracy: 0.6336 - val_loss: 0.0822\nEpoch 78/100\n\nEpoch 78: val_accuracy improved from 0.63903 to 0.64426, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7288 - loss: 0.0527 - val_accuracy: 0.6443 - val_loss: 0.0803\nEpoch 79/100\n\nEpoch 79: val_accuracy did not improve from 0.64426\n810/810 - 77s - 95ms/step - accuracy: 0.7285 - loss: 0.0529 - val_accuracy: 0.6423 - val_loss: 0.0798\nEpoch 80/100\n\nEpoch 80: val_accuracy did not improve from 0.64426\n810/810 - 77s - 95ms/step - accuracy: 0.7310 - loss: 0.0524 - val_accuracy: 0.6308 - val_loss: 0.0819\nEpoch 81/100\n\nEpoch 81: val_accuracy improved from 0.64426 to 0.64577, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7264 - loss: 0.0534 - val_accuracy: 0.6458 - val_loss: 0.0788\nEpoch 82/100\n\nEpoch 82: val_accuracy did not improve from 0.64577\n810/810 - 77s - 95ms/step - accuracy: 0.7335 - loss: 0.0517 - val_accuracy: 0.6287 - val_loss: 0.0834\nEpoch 83/100\n\nEpoch 83: val_accuracy did not improve from 0.64577\n810/810 - 77s - 95ms/step - accuracy: 0.7347 - loss: 0.0518 - val_accuracy: 0.6429 - val_loss: 0.0805\nEpoch 84/100\n\nEpoch 84: val_accuracy did not improve from 0.64577\n810/810 - 77s - 95ms/step - accuracy: 0.7379 - loss: 0.0510 - val_accuracy: 0.6311 - val_loss: 0.0839\nEpoch 85/100\n\nEpoch 85: val_accuracy did not improve from 0.64577\n810/810 - 77s - 95ms/step - accuracy: 0.7343 - loss: 0.0517 - val_accuracy: 0.6427 - val_loss: 0.0804\nEpoch 86/100\n\nEpoch 86: val_accuracy improved from 0.64577 to 0.65625, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 95ms/step - accuracy: 0.7382 - loss: 0.0507 - val_accuracy: 0.6562 - val_loss: 0.0777\nEpoch 87/100\n\nEpoch 87: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7393 - loss: 0.0505 - val_accuracy: 0.6374 - val_loss: 0.0824\nEpoch 88/100\n\nEpoch 88: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7387 - loss: 0.0507 - val_accuracy: 0.6424 - val_loss: 0.0818\nEpoch 89/100\n\nEpoch 89: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7407 - loss: 0.0501 - val_accuracy: 0.6481 - val_loss: 0.0796\nEpoch 90/100\n\nEpoch 90: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7414 - loss: 0.0502 - val_accuracy: 0.6494 - val_loss: 0.0783\nEpoch 91/100\n\nEpoch 91: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7442 - loss: 0.0495 - val_accuracy: 0.6536 - val_loss: 0.0786\nEpoch 92/100\n\nEpoch 92: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7448 - loss: 0.0492 - val_accuracy: 0.6514 - val_loss: 0.0793\nEpoch 93/100\n\nEpoch 93: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7474 - loss: 0.0488 - val_accuracy: 0.6540 - val_loss: 0.0784\nEpoch 94/100\n\nEpoch 94: val_accuracy did not improve from 0.65625\n810/810 - 77s - 95ms/step - accuracy: 0.7481 - loss: 0.0485 - val_accuracy: 0.6508 - val_loss: 0.0802\nEpoch 95/100\n\nEpoch 95: val_accuracy improved from 0.65625 to 0.65879, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7478 - loss: 0.0486 - val_accuracy: 0.6588 - val_loss: 0.0772\nEpoch 96/100\n\nEpoch 96: val_accuracy did not improve from 0.65879\n810/810 - 77s - 95ms/step - accuracy: 0.7484 - loss: 0.0483 - val_accuracy: 0.6584 - val_loss: 0.0785\nEpoch 97/100\n\nEpoch 97: val_accuracy improved from 0.65879 to 0.66007, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7478 - loss: 0.0485 - val_accuracy: 0.6601 - val_loss: 0.0762\nEpoch 98/100\n\nEpoch 98: val_accuracy did not improve from 0.66007\n810/810 - 77s - 95ms/step - accuracy: 0.7514 - loss: 0.0479 - val_accuracy: 0.6599 - val_loss: 0.0781\nEpoch 99/100\n\nEpoch 99: val_accuracy improved from 0.66007 to 0.66144, saving model to checkpoints/best_model_v4.keras\n810/810 - 77s - 96ms/step - accuracy: 0.7507 - loss: 0.0479 - val_accuracy: 0.6614 - val_loss: 0.0776\nEpoch 100/100\n\nEpoch 100: val_accuracy did not improve from 0.66144\n810/810 - 77s - 95ms/step - accuracy: 0.7461 - loss: 0.0490 - val_accuracy: 0.6603 - val_loss: 0.0770\nRestoring model weights from the end of the best epoch: 99.\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f6826ebdd90>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"import shutil\n\n# 1. Zip the entire checkpoints folder\nshutil.make_archive('/kaggle/working/checkpoints_backup_v3', 'zip', '/kaggle/working/checkpoints')","metadata":{"trusted":true,"id":"FDBNCzu1vXcA","execution":{"iopub.status.busy":"2025-05-23T09:16:43.403882Z","iopub.execute_input":"2025-05-23T09:16:43.404074Z","iopub.status.idle":"2025-05-23T09:16:43.473256Z","shell.execute_reply.started":"2025-05-23T09:16:43.404058Z","shell.execute_reply":"2025-05-23T09:16:43.472650Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoints_backup_v3.zip'"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"@register_keras_serializable()\ndef attention_context(x):\n    return tf.reduce_sum(x[0] * x[1], axis=1)\n\n@register_keras_serializable()\ndef attention_output_shape(input_shapes):\n    return (input_shapes[0][0], input_shapes[0][2])\n\n@register_keras_serializable(name=\"loss\")\ndef focal_loss_wrapper(gamma=2.0, alpha=0.25):\n    def loss(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, 1e-8, 1. - 1e-8)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        weight = alpha * tf.pow(1 - y_pred, gamma)\n        loss = weight * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:46:57.795660Z","iopub.execute_input":"2025-05-25T16:46:57.796682Z","iopub.status.idle":"2025-05-25T16:46:57.803656Z","shell.execute_reply.started":"2025-05-25T16:46:57.796638Z","shell.execute_reply":"2025-05-25T16:46:57.802672Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from keras.models import load_model\n\nmodel = load_model(\n    'checkpoints/best_model_v4.keras',\n    custom_objects={\n        'loss': focal_loss_wrapper(),\n        'attention_context': attention_context,\n        'attention_output_shape': attention_output_shape\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:27:48.934167Z","iopub.execute_input":"2025-05-23T09:27:48.935024Z","iopub.status.idle":"2025-05-23T09:27:49.300792Z","shell.execute_reply.started":"2025-05-23T09:27:48.934999Z","shell.execute_reply":"2025-05-23T09:27:49.300011Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"from keras.models import load_model\n\nmodel = load_model(\n    '/kaggle/input/best_model_v4.keras/keras/default/1/best_model_v4.keras',\n    custom_objects={\n        'loss': focal_loss_wrapper(),\n        'attention_context': attention_context,\n        'attention_output_shape': attention_output_shape\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T16:47:09.517346Z","iopub.execute_input":"2025-05-25T16:47:09.517663Z","iopub.status.idle":"2025-05-25T16:47:10.139875Z","shell.execute_reply.started":"2025-05-25T16:47:09.517635Z","shell.execute_reply":"2025-05-25T16:47:10.138931Z"}},"outputs":[{"name":"stderr","text":"2025-05-25 16:47:09.562386: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\n# Предсказания\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\ny_true = np.argmax(y_test, axis=1)\n\n# Отчёт по классам\nprint(classification_report(y_true, y_pred, target_names=['Down', 'Neutral', 'Up'], digits=4))","metadata":{"trusted":true,"id":"0clcihOivXcA","execution":{"iopub.status.busy":"2025-05-25T16:47:12.857517Z","iopub.execute_input":"2025-05-25T16:47:12.857907Z","iopub.status.idle":"2025-05-25T16:48:24.460083Z","shell.execute_reply.started":"2025-05-25T16:47:12.857882Z","shell.execute_reply":"2025-05-25T16:48:24.458547Z"}},"outputs":[{"name":"stderr","text":"2025-05-25 16:47:15.898142: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1620/1620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 41ms/step\n              precision    recall  f1-score   support\n\n        Down     0.6997    0.7361    0.7174     27485\n     Neutral     0.6438    0.5147    0.5720     12214\n          Up     0.5904    0.6399    0.6142     12117\n\n    accuracy                         0.6614     51816\n   macro avg     0.6446    0.6302    0.6345     51816\nweighted avg     0.6609    0.6614    0.6590     51816\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Матрица ошибок\ncm = confusion_matrix(y_true, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Down', 'Neutral', 'Up'])\ndisp.plot(cmap='Blues', values_format='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"id":"bKMVgampvXcA","execution":{"iopub.status.busy":"2025-05-25T16:49:46.770031Z","iopub.execute_input":"2025-05-25T16:49:46.770349Z","iopub.status.idle":"2025-05-25T16:49:47.113370Z","shell.execute_reply.started":"2025-05-25T16:49:46.770325Z","shell.execute_reply":"2025-05-25T16:49:47.112125Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true,"id":"-Gj5vXGOvXcA"},"outputs":[],"execution_count":null}]}